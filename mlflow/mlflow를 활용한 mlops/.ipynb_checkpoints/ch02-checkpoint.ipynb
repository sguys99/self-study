{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5b472a1",
   "metadata": {},
   "source": [
    "## ch02"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d69857",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> Initial upload: 2022.03.28 </div>\n",
    "<div style=\"text-align: right\"> Last update: 2022.03.28</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "18345158",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings; warnings.filterwarnings('ignore')\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "\n",
    "# Options for pandas\n",
    "pd.options.display.max_columns = 50\n",
    "\n",
    "from pylab import rcParams\n",
    "\n",
    "rcParams['figure.figsize'] = 14, 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85c5754f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, plot_roc_curve, confusion_matrix\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cefa448e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "83f6515f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>-0.551600</td>\n",
       "      <td>-0.617801</td>\n",
       "      <td>-0.991390</td>\n",
       "      <td>-0.311169</td>\n",
       "      <td>1.468177</td>\n",
       "      <td>-0.470401</td>\n",
       "      <td>0.207971</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>1.612727</td>\n",
       "      <td>1.065235</td>\n",
       "      <td>0.489095</td>\n",
       "      <td>-0.143772</td>\n",
       "      <td>0.635558</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>-0.114805</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>0.624501</td>\n",
       "      <td>0.066084</td>\n",
       "      <td>0.717293</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>2.345865</td>\n",
       "      <td>-2.890083</td>\n",
       "      <td>1.109969</td>\n",
       "      <td>-0.121359</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>-0.226487</td>\n",
       "      <td>0.178228</td>\n",
       "      <td>0.507757</td>\n",
       "      <td>-0.287924</td>\n",
       "      <td>-0.631418</td>\n",
       "      <td>-1.059647</td>\n",
       "      <td>-0.684093</td>\n",
       "      <td>1.965775</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>-0.822843</td>\n",
       "      <td>0.538196</td>\n",
       "      <td>1.345852</td>\n",
       "      <td>-1.119670</td>\n",
       "      <td>0.175121</td>\n",
       "      <td>-0.451449</td>\n",
       "      <td>-0.237033</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10       V11       V12       V13       V14  \\\n",
       "0  0.098698  0.363787  0.090794 -0.551600 -0.617801 -0.991390 -0.311169   \n",
       "1  0.085102 -0.255425 -0.166974  1.612727  1.065235  0.489095 -0.143772   \n",
       "2  0.247676 -1.514654  0.207643  0.624501  0.066084  0.717293 -0.165946   \n",
       "3  0.377436 -1.387024 -0.054952 -0.226487  0.178228  0.507757 -0.287924   \n",
       "4 -0.270533  0.817739  0.753074 -0.822843  0.538196  1.345852 -1.119670   \n",
       "\n",
       "        V15       V16       V17       V18       V19       V20       V21  \\\n",
       "0  1.468177 -0.470401  0.207971  0.025791  0.403993  0.251412 -0.018307   \n",
       "1  0.635558  0.463917 -0.114805 -0.183361 -0.145783 -0.069083 -0.225775   \n",
       "2  2.345865 -2.890083  1.109969 -0.121359 -2.261857  0.524980  0.247998   \n",
       "3 -0.631418 -1.059647 -0.684093  1.965775 -1.232622 -0.208038 -0.108300   \n",
       "4  0.175121 -0.451449 -0.237033 -0.038195  0.803487  0.408542 -0.009431   \n",
       "\n",
       "        V22       V23       V24       V25       V26       V27       V28  \\\n",
       "0  0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053   \n",
       "1 -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724   \n",
       "2  0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752   \n",
       "3  0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458   \n",
       "4  0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   \n",
       "\n",
       "   Amount  Class  \n",
       "0  149.62      0  \n",
       "1    2.69      0  \n",
       "2  378.66      0  \n",
       "3  123.50      0  \n",
       "4   69.99      0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5cd02cfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>3.918649e-15</td>\n",
       "      <td>5.682686e-16</td>\n",
       "      <td>-8.761736e-15</td>\n",
       "      <td>2.811118e-15</td>\n",
       "      <td>-1.552103e-15</td>\n",
       "      <td>2.040130e-15</td>\n",
       "      <td>-1.698953e-15</td>\n",
       "      <td>-1.893285e-16</td>\n",
       "      <td>-3.147640e-15</td>\n",
       "      <td>1.772925e-15</td>\n",
       "      <td>9.289524e-16</td>\n",
       "      <td>-1.803266e-15</td>\n",
       "      <td>1.674888e-15</td>\n",
       "      <td>1.475621e-15</td>\n",
       "      <td>3.501098e-15</td>\n",
       "      <td>1.392460e-15</td>\n",
       "      <td>-7.466538e-16</td>\n",
       "      <td>4.258754e-16</td>\n",
       "      <td>9.019919e-16</td>\n",
       "      <td>5.126845e-16</td>\n",
       "      <td>1.473120e-16</td>\n",
       "      <td>8.042109e-16</td>\n",
       "      <td>5.282512e-16</td>\n",
       "      <td>4.456271e-15</td>\n",
       "      <td>1.426896e-15</td>\n",
       "      <td>1.701640e-15</td>\n",
       "      <td>-3.662252e-16</td>\n",
       "      <td>-1.217809e-16</td>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>1.088850e+00</td>\n",
       "      <td>1.020713e+00</td>\n",
       "      <td>9.992014e-01</td>\n",
       "      <td>9.952742e-01</td>\n",
       "      <td>9.585956e-01</td>\n",
       "      <td>9.153160e-01</td>\n",
       "      <td>8.762529e-01</td>\n",
       "      <td>8.493371e-01</td>\n",
       "      <td>8.381762e-01</td>\n",
       "      <td>8.140405e-01</td>\n",
       "      <td>7.709250e-01</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>-2.458826e+01</td>\n",
       "      <td>-4.797473e+00</td>\n",
       "      <td>-1.868371e+01</td>\n",
       "      <td>-5.791881e+00</td>\n",
       "      <td>-1.921433e+01</td>\n",
       "      <td>-4.498945e+00</td>\n",
       "      <td>-1.412985e+01</td>\n",
       "      <td>-2.516280e+01</td>\n",
       "      <td>-9.498746e+00</td>\n",
       "      <td>-7.213527e+00</td>\n",
       "      <td>-5.449772e+01</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>-5.354257e-01</td>\n",
       "      <td>-7.624942e-01</td>\n",
       "      <td>-4.055715e-01</td>\n",
       "      <td>-6.485393e-01</td>\n",
       "      <td>-4.255740e-01</td>\n",
       "      <td>-5.828843e-01</td>\n",
       "      <td>-4.680368e-01</td>\n",
       "      <td>-4.837483e-01</td>\n",
       "      <td>-4.988498e-01</td>\n",
       "      <td>-4.562989e-01</td>\n",
       "      <td>-2.117214e-01</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>-9.291738e-02</td>\n",
       "      <td>-3.275735e-02</td>\n",
       "      <td>1.400326e-01</td>\n",
       "      <td>-1.356806e-02</td>\n",
       "      <td>5.060132e-02</td>\n",
       "      <td>4.807155e-02</td>\n",
       "      <td>6.641332e-02</td>\n",
       "      <td>-6.567575e-02</td>\n",
       "      <td>-3.636312e-03</td>\n",
       "      <td>3.734823e-03</td>\n",
       "      <td>-6.248109e-02</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>4.539234e-01</td>\n",
       "      <td>7.395934e-01</td>\n",
       "      <td>6.182380e-01</td>\n",
       "      <td>6.625050e-01</td>\n",
       "      <td>4.931498e-01</td>\n",
       "      <td>6.488208e-01</td>\n",
       "      <td>5.232963e-01</td>\n",
       "      <td>3.996750e-01</td>\n",
       "      <td>5.008067e-01</td>\n",
       "      <td>4.589494e-01</td>\n",
       "      <td>1.330408e-01</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>2.374514e+01</td>\n",
       "      <td>1.201891e+01</td>\n",
       "      <td>7.848392e+00</td>\n",
       "      <td>7.126883e+00</td>\n",
       "      <td>1.052677e+01</td>\n",
       "      <td>8.877742e+00</td>\n",
       "      <td>1.731511e+01</td>\n",
       "      <td>9.253526e+00</td>\n",
       "      <td>5.041069e+00</td>\n",
       "      <td>5.591971e+00</td>\n",
       "      <td>3.942090e+01</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4  \\\n",
       "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean    94813.859575  3.918649e-15  5.682686e-16 -8.761736e-15  2.811118e-15   \n",
       "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
       "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
       "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
       "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
       "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
       "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean  -1.552103e-15  2.040130e-15 -1.698953e-15 -1.893285e-16 -3.147640e-15   \n",
       "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
       "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
       "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
       "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
       "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
       "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
       "\n",
       "                V10           V11           V12           V13           V14  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   1.772925e-15  9.289524e-16 -1.803266e-15  1.674888e-15  1.475621e-15   \n",
       "std    1.088850e+00  1.020713e+00  9.992014e-01  9.952742e-01  9.585956e-01   \n",
       "min   -2.458826e+01 -4.797473e+00 -1.868371e+01 -5.791881e+00 -1.921433e+01   \n",
       "25%   -5.354257e-01 -7.624942e-01 -4.055715e-01 -6.485393e-01 -4.255740e-01   \n",
       "50%   -9.291738e-02 -3.275735e-02  1.400326e-01 -1.356806e-02  5.060132e-02   \n",
       "75%    4.539234e-01  7.395934e-01  6.182380e-01  6.625050e-01  4.931498e-01   \n",
       "max    2.374514e+01  1.201891e+01  7.848392e+00  7.126883e+00  1.052677e+01   \n",
       "\n",
       "                V15           V16           V17           V18           V19  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   3.501098e-15  1.392460e-15 -7.466538e-16  4.258754e-16  9.019919e-16   \n",
       "std    9.153160e-01  8.762529e-01  8.493371e-01  8.381762e-01  8.140405e-01   \n",
       "min   -4.498945e+00 -1.412985e+01 -2.516280e+01 -9.498746e+00 -7.213527e+00   \n",
       "25%   -5.828843e-01 -4.680368e-01 -4.837483e-01 -4.988498e-01 -4.562989e-01   \n",
       "50%    4.807155e-02  6.641332e-02 -6.567575e-02 -3.636312e-03  3.734823e-03   \n",
       "75%    6.488208e-01  5.232963e-01  3.996750e-01  5.008067e-01  4.589494e-01   \n",
       "max    8.877742e+00  1.731511e+01  9.253526e+00  5.041069e+00  5.591971e+00   \n",
       "\n",
       "                V20           V21           V22           V23           V24  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   5.126845e-16  1.473120e-16  8.042109e-16  5.282512e-16  4.456271e-15   \n",
       "std    7.709250e-01  7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
       "min   -5.449772e+01 -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
       "25%   -2.117214e-01 -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
       "50%   -6.248109e-02 -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
       "75%    1.330408e-01  1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
       "max    3.942090e+01  2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
       "\n",
       "                V25           V26           V27           V28         Amount  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
       "mean   1.426896e-15  1.701640e-15 -3.662252e-16 -1.217809e-16      88.349619   \n",
       "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
       "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
       "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
       "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
       "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
       "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
       "\n",
       "               Class  \n",
       "count  284807.000000  \n",
       "mean        0.001727  \n",
       "std         0.041527  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "346ca420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 31)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "95e0b03b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86f1159",
   "metadata": {},
   "source": [
    "정상데이터 수를 줄여서 이상데이터 비율을 높이자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b7ca56aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal = df[df['Class']==0].sample(frac=0.5, random_state=2020).reset_index(drop=True) # 랜덤 샘플링 결과를 반복횟수와 관계없이 동일하게 지정하기 위해 random_state 지정, 재현성에 도움\n",
    "anomaly = df[df['Class']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "01896c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomalies: (492, 31)\n",
      "Normal: (142158, 31)\n"
     ]
    }
   ],
   "source": [
    "print(f'Anomalies: {anomaly.shape}')\n",
    "print(f'Normal: {normal.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63869df",
   "metadata": {},
   "source": [
    "- 여전히 차이가 존재한다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71487e0",
   "metadata": {},
   "source": [
    "한가지 해결책이 있는데 비정상을 분류할 때 가중치를 높게 주는 것이다.  \n",
    "뒤에서 설명"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58e8a0c",
   "metadata": {},
   "source": [
    "일단 정상, 비정상 데이터를 분리하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "456f467f",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_train, normal_test = train_test_split(normal, test_size=0.2, random_state=2020)\n",
    "anomaly_train, anomaly_test = train_test_split(anomaly, test_size=0.2, random_state=2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ffc682",
   "metadata": {},
   "source": [
    "학습 데이터를 다시 validation 데이터로 분리하자. 그러면 비율이 6:2:2가 되도록...  \n",
    "그러기 위해서는 test_size = 0.25로 지정하면 된다. 0.25*0.8 = 0.2        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c02977f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "noraml_train, normal_validate = train_test_split(normal_train, test_size=0.25, random_state=2020)\n",
    "anomaly_train, anomaly_validate = train_test_split(anomaly_train, test_size=0.25, random_state=2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f708ba2",
   "metadata": {},
   "source": [
    "이제 X_train, X_test, X_validate를 정의하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dd7ea2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat((normal_train, anomaly_train))\n",
    "X_test = pd.concat((normal_test, anomaly_test))\n",
    "X_validate = pd.concat((normal_validate, anomaly_validate))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e8c289",
   "metadata": {},
   "source": [
    "X, y 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e3a7b91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(X_train['Class'])\n",
    "y_test = np.array(X_test['Class'])\n",
    "y_validate = np.array(X_validate['Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ef0ddf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop('Class', axis = 1)\n",
    "X_test = X_test.drop('Class', axis = 1)\n",
    "X_validate = X_validate.drop('Class', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e24e32f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(114020, 30)\n",
      "(28531, 30)\n",
      "(28531, 30)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_validate.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df86c78",
   "metadata": {},
   "source": [
    "정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9389e81e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit((pd.concat((normal, anomaly))).drop('Class', axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ff918ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_validate = scaler.transform(X_validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5a0979",
   "metadata": {},
   "source": [
    "### 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "90172171",
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_model = LogisticRegression(random_state=None, max_iter=400, \n",
    "                             solver='newton-cg').fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308124f8",
   "metadata": {},
   "source": [
    "### 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0c8208f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_acc = sk_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1a222821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.998598016192913"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5802f27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = sk_model.predict(X_test)\n",
    "auc_score = roc_auc_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cc76dab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.828177313370054\n",
      "0.998598016192913\n"
     ]
    }
   ],
   "source": [
    "print(auc_score)\n",
    "print(eval_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "12781d4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "roc_plot = plot_roc_curve(sk_model, X_test, y_test, name='Scikit-learn ROC Curve')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d52b90",
   "metadata": {},
   "source": [
    "conf matrix 구현해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "86afb4f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 51.0, 'Predicted')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(y_test, preds)\n",
    "ax = sns.heatmap(conf_matrix, annot = True, fmt = 'g')\n",
    "ax.invert_xaxis()\n",
    "ax.invert_yaxis()\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d86cce0",
   "metadata": {},
   "source": [
    "- positive 검출 정확도가 낮다..??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77acdce0",
   "metadata": {},
   "source": [
    "### 모델 검증"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe9a171",
   "metadata": {},
   "source": [
    "가중치 목록을 정의하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6fbea064",
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_weights = [1, 5, 10, 15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c03fa419",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_folds = 5\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True, random_state=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1dfbafe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KFold(n_splits=5, random_state=2020, shuffle=True)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "69944c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      " fold 1 \n",
      " Anomaly Weight: 1\n",
      "AUC 0.8\n",
      " eval_acc: 0.9985982127212195\n",
      "----------------------------------------\n",
      " fold 2 \n",
      " Anomaly Weight: 1\n",
      "AUC 0.8568790049001132\n",
      " eval_acc: 0.998422712933754\n",
      "----------------------------------------\n",
      " fold 3 \n",
      " Anomaly Weight: 1\n",
      "AUC 0.8179179195189047\n",
      " eval_acc: 0.9980722046968104\n",
      "----------------------------------------\n",
      " fold 4 \n",
      " Anomaly Weight: 1\n",
      "AUC 0.8682452129973255\n",
      " eval_acc: 0.9987732211706976\n",
      "----------------------------------------\n",
      " fold 5 \n",
      " Anomaly Weight: 1\n",
      "AUC 0.8528532875621686\n",
      " eval_acc: 0.9989484752891693\n",
      "\n",
      "Averages: \n",
      "Accuracy:  0.9985629653623302\n",
      "AUC:  0.8391790849957024\n",
      "Best: \n",
      "Accuracy:  0.9989484752891693\n",
      "AUC:  0.8682452129973255\n",
      "----------------------------------------\n",
      " fold 1 \n",
      " Anomaly Weight: 5\n",
      "AUC 0.8748241603657465\n",
      " eval_acc: 0.9987734361310671\n",
      "----------------------------------------\n",
      " fold 2 \n",
      " Anomaly Weight: 5\n",
      "AUC 0.9515893956527202\n",
      " eval_acc: 0.9980722046968104\n",
      "----------------------------------------\n",
      " fold 3 \n",
      " Anomaly Weight: 5\n",
      "AUC 0.9314663169342972\n",
      " eval_acc: 0.9987732211706976\n",
      "----------------------------------------\n",
      " fold 4 \n",
      " Anomaly Weight: 5\n",
      "AUC 0.8943851628367561\n",
      " eval_acc: 0.9985979670522257\n",
      "----------------------------------------\n",
      " fold 5 \n",
      " Anomaly Weight: 5\n",
      "AUC 0.8820013855427915\n",
      " eval_acc: 0.9985979670522257\n",
      "\n",
      "Averages: \n",
      "Accuracy:  0.9985629592206052\n",
      "AUC:  0.9068532842664622\n",
      "Best: \n",
      "Accuracy:  0.9987734361310671\n",
      "AUC:  0.9515893956527202\n",
      "----------------------------------------\n",
      " fold 1 \n",
      " Anomaly Weight: 10\n",
      "AUC 0.9245604009143662\n",
      " eval_acc: 0.9985982127212195\n",
      "----------------------------------------\n",
      " fold 2 \n",
      " Anomaly Weight: 10\n",
      "AUC 0.9751350672194998\n",
      " eval_acc: 0.9977216964598669\n",
      "----------------------------------------\n",
      " fold 3 \n",
      " Anomaly Weight: 10\n",
      "AUC 0.9313783507133262\n",
      " eval_acc: 0.9985979670522257\n",
      "----------------------------------------\n",
      " fold 4 \n",
      " Anomaly Weight: 10\n",
      "AUC 0.8942972430196292\n",
      " eval_acc: 0.998422712933754\n",
      "----------------------------------------\n",
      " fold 5 \n",
      " Anomaly Weight: 10\n",
      "AUC 0.8820013855427915\n",
      " eval_acc: 0.9985979670522257\n",
      "\n",
      "Averages: \n",
      "Accuracy:  0.9983877112438584\n",
      "AUC:  0.9214744894819227\n",
      "Best: \n",
      "Accuracy:  0.9985982127212195\n",
      "AUC:  0.9751350672194998\n",
      "----------------------------------------\n",
      " fold 1 \n",
      " Anomaly Weight: 15\n",
      "AUC 0.9242087216458591\n",
      " eval_acc: 0.9978973190818293\n",
      "----------------------------------------\n",
      " fold 2 \n",
      " Anomaly Weight: 15\n",
      "AUC 0.9749591657243373\n",
      " eval_acc: 0.9973711882229233\n",
      "----------------------------------------\n",
      " fold 3 \n",
      " Anomaly Weight: 15\n",
      "AUC 0.9313783507133262\n",
      " eval_acc: 0.9985979670522257\n",
      "----------------------------------------\n",
      " fold 4 \n",
      " Anomaly Weight: 15\n",
      "AUC 0.8938576439339954\n",
      " eval_acc: 0.997546442341395\n",
      "----------------------------------------\n",
      " fold 5 \n",
      " Anomaly Weight: 15\n",
      "AUC 0.8813861631838532\n",
      " eval_acc: 0.9973711882229233\n",
      "\n",
      "Averages: \n",
      "Accuracy:  0.9977568209842593\n",
      "AUC:  0.9211580090402742\n",
      "Best: \n",
      "Accuracy:  0.9985979670522257\n",
      "AUC:  0.9749591657243373\n"
     ]
    }
   ],
   "source": [
    "logs = []\n",
    "for f in range(len(anomaly_weights)):\n",
    "    fold = 1\n",
    "    accuracies = []\n",
    "    auc_scores = []\n",
    "    for train, test in kfold.split(X_validate, y_validate):\n",
    "        weight = anomaly_weights[f]\n",
    "        class_weights = {0:1,\n",
    "                        1:weight}\n",
    "        \n",
    "        sk_model = LogisticRegression(random_state=2020, max_iter=400, solver='newton-cg', \n",
    "                                      class_weight=class_weights).fit(X_validate[train], y_validate[train])\n",
    "        \n",
    "        for h in range(40): \n",
    "            print('-', end='')\n",
    "            \n",
    "        print(f'\\n fold {fold} \\n Anomaly Weight: {weight}')\n",
    "        eval_acc = sk_model.score(X_validate[test], y_validate[test])\n",
    "        preds = sk_model.predict(X_validate[test])\n",
    "        \n",
    "        try: \n",
    "            auc_score = roc_auc_score(y_validate[test], preds)\n",
    "        except:\n",
    "            auc_score = -1\n",
    "            \n",
    "        print('AUC {}\\n eval_acc: {}'.format(auc_score, eval_acc))\n",
    "        accuracies.append(eval_acc)\n",
    "        auc_scores.append(auc_score)\n",
    "        log = [sk_model, X_validate[test], y_validate[test], preds]\n",
    "        logs.append(log)\n",
    "        fold = fold + 1\n",
    "        \n",
    "    print('\\nAverages: ')\n",
    "    print('Accuracy: ', np.mean(accuracies))\n",
    "    print('AUC: ', np.mean(auc_scores))\n",
    "    print('Best: ')\n",
    "    print('Accuracy: ', np.max(accuracies))\n",
    "    print('AUC: ', np.max(auc_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4d165f",
   "metadata": {},
   "source": [
    "- 가중치 10일 때 성능이 가장 좋았다..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4698be01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[LogisticRegression(class_weight={0: 1, 1: 1}, max_iter=400, random_state=2020,\n",
       "                     solver='newton-cg'),\n",
       "  array([[-0.41687478, -0.41084269, -0.08754479, ..., -0.18544762,\n",
       "           0.03349597, -0.29826571],\n",
       "         [-0.76564508,  0.08464212,  0.31399002, ...,  0.48540645,\n",
       "           0.59267849, -0.30802347],\n",
       "         [ 0.9489075 , -0.07104259,  0.02631749, ..., -0.09700922,\n",
       "           0.22768298,  0.62483371],\n",
       "         ...,\n",
       "         [ 0.44996463,  0.48439914,  0.80397445, ...,  1.52472442,\n",
       "           0.95834616, -0.09416919],\n",
       "         [ 1.22012191,  0.03008983,  0.79000055, ..., -0.72391981,\n",
       "          -0.67660207, -0.33725787],\n",
       "         [-1.83080897,  0.16432594,  2.30200126, ...,  1.26542712,\n",
       "           1.22252867, -0.34297257]]),\n",
       "  array([0, 0, 0, ..., 1, 1, 1], dtype=int64),\n",
       "  array([0, 0, 0, ..., 1, 0, 1], dtype=int64)],\n",
       " [LogisticRegression(class_weight={0: 1, 1: 1}, max_iter=400, random_state=2020,\n",
       "                     solver='newton-cg'),\n",
       "  array([[ 0.49941964,  0.02151323,  0.3280098 , ...,  0.64741135,\n",
       "           0.27257746, -0.33683024],\n",
       "         [ 1.49156751,  1.10951068, -0.43923953, ..., -0.20967175,\n",
       "          -0.20843444, -0.07861898],\n",
       "         [-1.02546781,  0.66332729, -0.30982762, ...,  0.0536541 ,\n",
       "           0.0630172 , -0.21452783],\n",
       "         ...,\n",
       "         [-1.74509816, -1.96398531,  4.29277308, ...,  4.58560472,\n",
       "           2.66048655, -0.34297257],\n",
       "         [ 0.82122403,  0.59941843,  1.89828593, ...,  1.19084328,\n",
       "           0.98935501, -0.34686013],\n",
       "         [ 0.73877098,  0.7741523 , -0.31729507, ..., -0.03670837,\n",
       "           0.12551102,  0.72676535]]),\n",
       "  array([0, 0, 0, ..., 1, 1, 1], dtype=int64),\n",
       "  array([0, 0, 0, ..., 1, 1, 0], dtype=int64)],\n",
       " [LogisticRegression(class_weight={0: 1, 1: 1}, max_iter=400, random_state=2020,\n",
       "                     solver='newton-cg'),\n",
       "  array([[ 0.47133979,  0.53378354, -1.10191569, ..., -0.38198636,\n",
       "          -0.03919747,  1.55804078],\n",
       "         [ 1.33437497, -0.7915194 , -0.55046057, ..., -0.30388782,\n",
       "          -0.92463475,  0.62502809],\n",
       "         [-1.48248005, -0.22099397,  1.04404195, ..., -1.83626616,\n",
       "          -0.8684705 , -0.34619924],\n",
       "         ...,\n",
       "         [ 0.71067011,  0.46410728,  0.80647895, ...,  1.59144971,\n",
       "           0.97112732, -0.08289529],\n",
       "         [-1.55967864, -7.99739178,  5.30762033, ...,  5.20666849,\n",
       "          -4.29673913, -0.34297257],\n",
       "         [ 1.00330171, -1.69922815,  0.05708437, ...,  2.52546729,\n",
       "           0.01140104,  0.89719566]]),\n",
       "  array([0, 0, 0, ..., 1, 1, 1], dtype=int64),\n",
       "  array([0, 0, 0, ..., 1, 1, 1], dtype=int64)],\n",
       " [LogisticRegression(class_weight={0: 1, 1: 1}, max_iter=400, random_state=2020,\n",
       "                     solver='newton-cg'),\n",
       "  array([[-0.67352382,  0.51826225, -0.98539269, ...,  0.14606111,\n",
       "           0.07643378,  0.32102146],\n",
       "         [ 1.17108725,  0.05977242,  0.5049858 , ...,  0.51091541,\n",
       "           0.20253602, -0.32357368],\n",
       "         [ 1.12707586,  0.69000508, -0.73439   , ..., -0.21991664,\n",
       "          -0.00808572,  1.05036525],\n",
       "         ...,\n",
       "         [-1.59669108, -7.78477886,  4.5187322 , ...,  5.5149345 ,\n",
       "          -3.5853159 , -0.34297257],\n",
       "         [ 1.02516028, -1.37636993,  2.00150636, ...,  1.25513882,\n",
       "           0.4270082 , -0.34297257],\n",
       "         [-1.1243358 , -2.99665901,  2.76351195, ...,  4.36749331,\n",
       "           1.12664791, -0.3262561 ]]),\n",
       "  array([0, 0, 0, ..., 1, 1, 1], dtype=int64),\n",
       "  array([0, 0, 0, ..., 1, 1, 1], dtype=int64)],\n",
       " [LogisticRegression(class_weight={0: 1, 1: 1}, max_iter=400, random_state=2020,\n",
       "                     solver='newton-cg'),\n",
       "  array([[-1.3297433 ,  0.49545292, -0.39552091, ..., -0.11849448,\n",
       "           0.11436705,  0.15852175],\n",
       "         [-0.28763599,  0.51299049, -0.32065229, ...,  0.2493946 ,\n",
       "           0.03698081, -0.24072993],\n",
       "         [-0.32824249,  0.08156748,  0.20529502, ...,  0.71444307,\n",
       "           0.76432157, -0.34686013],\n",
       "         ...,\n",
       "         [ 1.30366788, -0.06138917,  0.08268005, ...,  0.05363469,\n",
       "           0.3302583 ,  0.38053989],\n",
       "         [-0.97267095, -1.40737112, -0.88904315, ...,  0.1486905 ,\n",
       "           1.08391468,  0.46400565],\n",
       "         [-1.15449642, -0.48364193, -0.99752531, ..., -0.75062264,\n",
       "          -0.50225814,  2.67310756]]),\n",
       "  array([0, 0, 0, ..., 1, 1, 1], dtype=int64),\n",
       "  array([0, 0, 0, ..., 0, 0, 0], dtype=int64)],\n",
       " [LogisticRegression(class_weight={0: 1, 1: 5}, max_iter=400, random_state=2020,\n",
       "                     solver='newton-cg'),\n",
       "  array([[-0.41687478, -0.41084269, -0.08754479, ..., -0.18544762,\n",
       "           0.03349597, -0.29826571],\n",
       "         [-0.76564508,  0.08464212,  0.31399002, ...,  0.48540645,\n",
       "           0.59267849, -0.30802347],\n",
       "         [ 0.9489075 , -0.07104259,  0.02631749, ..., -0.09700922,\n",
       "           0.22768298,  0.62483371],\n",
       "         ...,\n",
       "         [ 0.44996463,  0.48439914,  0.80397445, ...,  1.52472442,\n",
       "           0.95834616, -0.09416919],\n",
       "         [ 1.22012191,  0.03008983,  0.79000055, ..., -0.72391981,\n",
       "          -0.67660207, -0.33725787],\n",
       "         [-1.83080897,  0.16432594,  2.30200126, ...,  1.26542712,\n",
       "           1.22252867, -0.34297257]]),\n",
       "  array([0, 0, 0, ..., 1, 1, 1], dtype=int64),\n",
       "  array([0, 0, 0, ..., 1, 0, 1], dtype=int64)],\n",
       " [LogisticRegression(class_weight={0: 1, 1: 5}, max_iter=400, random_state=2020,\n",
       "                     solver='newton-cg'),\n",
       "  array([[ 0.49941964,  0.02151323,  0.3280098 , ...,  0.64741135,\n",
       "           0.27257746, -0.33683024],\n",
       "         [ 1.49156751,  1.10951068, -0.43923953, ..., -0.20967175,\n",
       "          -0.20843444, -0.07861898],\n",
       "         [-1.02546781,  0.66332729, -0.30982762, ...,  0.0536541 ,\n",
       "           0.0630172 , -0.21452783],\n",
       "         ...,\n",
       "         [-1.74509816, -1.96398531,  4.29277308, ...,  4.58560472,\n",
       "           2.66048655, -0.34297257],\n",
       "         [ 0.82122403,  0.59941843,  1.89828593, ...,  1.19084328,\n",
       "           0.98935501, -0.34686013],\n",
       "         [ 0.73877098,  0.7741523 , -0.31729507, ..., -0.03670837,\n",
       "           0.12551102,  0.72676535]]),\n",
       "  array([0, 0, 0, ..., 1, 1, 1], dtype=int64),\n",
       "  array([0, 0, 0, ..., 1, 1, 0], dtype=int64)],\n",
       " [LogisticRegression(class_weight={0: 1, 1: 5}, max_iter=400, random_state=2020,\n",
       "                     solver='newton-cg'),\n",
       "  array([[ 0.47133979,  0.53378354, -1.10191569, ..., -0.38198636,\n",
       "          -0.03919747,  1.55804078],\n",
       "         [ 1.33437497, -0.7915194 , -0.55046057, ..., -0.30388782,\n",
       "          -0.92463475,  0.62502809],\n",
       "         [-1.48248005, -0.22099397,  1.04404195, ..., -1.83626616,\n",
       "          -0.8684705 , -0.34619924],\n",
       "         ...,\n",
       "         [ 0.71067011,  0.46410728,  0.80647895, ...,  1.59144971,\n",
       "           0.97112732, -0.08289529],\n",
       "         [-1.55967864, -7.99739178,  5.30762033, ...,  5.20666849,\n",
       "          -4.29673913, -0.34297257],\n",
       "         [ 1.00330171, -1.69922815,  0.05708437, ...,  2.52546729,\n",
       "           0.01140104,  0.89719566]]),\n",
       "  array([0, 0, 0, ..., 1, 1, 1], dtype=int64),\n",
       "  array([0, 0, 0, ..., 1, 1, 1], dtype=int64)],\n",
       " [LogisticRegression(class_weight={0: 1, 1: 5}, max_iter=400, random_state=2020,\n",
       "                     solver='newton-cg'),\n",
       "  array([[-0.67352382,  0.51826225, -0.98539269, ...,  0.14606111,\n",
       "           0.07643378,  0.32102146],\n",
       "         [ 1.17108725,  0.05977242,  0.5049858 , ...,  0.51091541,\n",
       "           0.20253602, -0.32357368],\n",
       "         [ 1.12707586,  0.69000508, -0.73439   , ..., -0.21991664,\n",
       "          -0.00808572,  1.05036525],\n",
       "         ...,\n",
       "         [-1.59669108, -7.78477886,  4.5187322 , ...,  5.5149345 ,\n",
       "          -3.5853159 , -0.34297257],\n",
       "         [ 1.02516028, -1.37636993,  2.00150636, ...,  1.25513882,\n",
       "           0.4270082 , -0.34297257],\n",
       "         [-1.1243358 , -2.99665901,  2.76351195, ...,  4.36749331,\n",
       "           1.12664791, -0.3262561 ]]),\n",
       "  array([0, 0, 0, ..., 1, 1, 1], dtype=int64),\n",
       "  array([0, 0, 0, ..., 1, 1, 1], dtype=int64)],\n",
       " [LogisticRegression(class_weight={0: 1, 1: 5}, max_iter=400, random_state=2020,\n",
       "                     solver='newton-cg'),\n",
       "  array([[-1.3297433 ,  0.49545292, -0.39552091, ..., -0.11849448,\n",
       "           0.11436705,  0.15852175],\n",
       "         [-0.28763599,  0.51299049, -0.32065229, ...,  0.2493946 ,\n",
       "           0.03698081, -0.24072993],\n",
       "         [-0.32824249,  0.08156748,  0.20529502, ...,  0.71444307,\n",
       "           0.76432157, -0.34686013],\n",
       "         ...,\n",
       "         [ 1.30366788, -0.06138917,  0.08268005, ...,  0.05363469,\n",
       "           0.3302583 ,  0.38053989],\n",
       "         [-0.97267095, -1.40737112, -0.88904315, ...,  0.1486905 ,\n",
       "           1.08391468,  0.46400565],\n",
       "         [-1.15449642, -0.48364193, -0.99752531, ..., -0.75062264,\n",
       "          -0.50225814,  2.67310756]]),\n",
       "  array([0, 0, 0, ..., 1, 1, 1], dtype=int64),\n",
       "  array([0, 0, 0, ..., 0, 0, 0], dtype=int64)],\n",
       " [LogisticRegression(class_weight={0: 1, 1: 10}, max_iter=400, random_state=2020,\n",
       "                     solver='newton-cg'),\n",
       "  array([[-0.41687478, -0.41084269, -0.08754479, ..., -0.18544762,\n",
       "           0.03349597, -0.29826571],\n",
       "         [-0.76564508,  0.08464212,  0.31399002, ...,  0.48540645,\n",
       "           0.59267849, -0.30802347],\n",
       "         [ 0.9489075 , -0.07104259,  0.02631749, ..., -0.09700922,\n",
       "           0.22768298,  0.62483371],\n",
       "         ...,\n",
       "         [ 0.44996463,  0.48439914,  0.80397445, ...,  1.52472442,\n",
       "           0.95834616, -0.09416919],\n",
       "         [ 1.22012191,  0.03008983,  0.79000055, ..., -0.72391981,\n",
       "          -0.67660207, -0.33725787],\n",
       "         [-1.83080897,  0.16432594,  2.30200126, ...,  1.26542712,\n",
       "           1.22252867, -0.34297257]]),\n",
       "  array([0, 0, 0, ..., 1, 1, 1], dtype=int64),\n",
       "  array([0, 0, 0, ..., 1, 0, 1], dtype=int64)],\n",
       " [LogisticRegression(class_weight={0: 1, 1: 10}, max_iter=400, random_state=2020,\n",
       "                     solver='newton-cg'),\n",
       "  array([[ 0.49941964,  0.02151323,  0.3280098 , ...,  0.64741135,\n",
       "           0.27257746, -0.33683024],\n",
       "         [ 1.49156751,  1.10951068, -0.43923953, ..., -0.20967175,\n",
       "          -0.20843444, -0.07861898],\n",
       "         [-1.02546781,  0.66332729, -0.30982762, ...,  0.0536541 ,\n",
       "           0.0630172 , -0.21452783],\n",
       "         ...,\n",
       "         [-1.74509816, -1.96398531,  4.29277308, ...,  4.58560472,\n",
       "           2.66048655, -0.34297257],\n",
       "         [ 0.82122403,  0.59941843,  1.89828593, ...,  1.19084328,\n",
       "           0.98935501, -0.34686013],\n",
       "         [ 0.73877098,  0.7741523 , -0.31729507, ..., -0.03670837,\n",
       "           0.12551102,  0.72676535]]),\n",
       "  array([0, 0, 0, ..., 1, 1, 1], dtype=int64),\n",
       "  array([0, 0, 0, ..., 1, 1, 0], dtype=int64)],\n",
       " [LogisticRegression(class_weight={0: 1, 1: 10}, max_iter=400, random_state=2020,\n",
       "                     solver='newton-cg'),\n",
       "  array([[ 0.47133979,  0.53378354, -1.10191569, ..., -0.38198636,\n",
       "          -0.03919747,  1.55804078],\n",
       "         [ 1.33437497, -0.7915194 , -0.55046057, ..., -0.30388782,\n",
       "          -0.92463475,  0.62502809],\n",
       "         [-1.48248005, -0.22099397,  1.04404195, ..., -1.83626616,\n",
       "          -0.8684705 , -0.34619924],\n",
       "         ...,\n",
       "         [ 0.71067011,  0.46410728,  0.80647895, ...,  1.59144971,\n",
       "           0.97112732, -0.08289529],\n",
       "         [-1.55967864, -7.99739178,  5.30762033, ...,  5.20666849,\n",
       "          -4.29673913, -0.34297257],\n",
       "         [ 1.00330171, -1.69922815,  0.05708437, ...,  2.52546729,\n",
       "           0.01140104,  0.89719566]]),\n",
       "  array([0, 0, 0, ..., 1, 1, 1], dtype=int64),\n",
       "  array([0, 0, 0, ..., 1, 1, 1], dtype=int64)],\n",
       " [LogisticRegression(class_weight={0: 1, 1: 10}, max_iter=400, random_state=2020,\n",
       "                     solver='newton-cg'),\n",
       "  array([[-0.67352382,  0.51826225, -0.98539269, ...,  0.14606111,\n",
       "           0.07643378,  0.32102146],\n",
       "         [ 1.17108725,  0.05977242,  0.5049858 , ...,  0.51091541,\n",
       "           0.20253602, -0.32357368],\n",
       "         [ 1.12707586,  0.69000508, -0.73439   , ..., -0.21991664,\n",
       "          -0.00808572,  1.05036525],\n",
       "         ...,\n",
       "         [-1.59669108, -7.78477886,  4.5187322 , ...,  5.5149345 ,\n",
       "          -3.5853159 , -0.34297257],\n",
       "         [ 1.02516028, -1.37636993,  2.00150636, ...,  1.25513882,\n",
       "           0.4270082 , -0.34297257],\n",
       "         [-1.1243358 , -2.99665901,  2.76351195, ...,  4.36749331,\n",
       "           1.12664791, -0.3262561 ]]),\n",
       "  array([0, 0, 0, ..., 1, 1, 1], dtype=int64),\n",
       "  array([0, 0, 0, ..., 1, 1, 1], dtype=int64)],\n",
       " [LogisticRegression(class_weight={0: 1, 1: 10}, max_iter=400, random_state=2020,\n",
       "                     solver='newton-cg'),\n",
       "  array([[-1.3297433 ,  0.49545292, -0.39552091, ..., -0.11849448,\n",
       "           0.11436705,  0.15852175],\n",
       "         [-0.28763599,  0.51299049, -0.32065229, ...,  0.2493946 ,\n",
       "           0.03698081, -0.24072993],\n",
       "         [-0.32824249,  0.08156748,  0.20529502, ...,  0.71444307,\n",
       "           0.76432157, -0.34686013],\n",
       "         ...,\n",
       "         [ 1.30366788, -0.06138917,  0.08268005, ...,  0.05363469,\n",
       "           0.3302583 ,  0.38053989],\n",
       "         [-0.97267095, -1.40737112, -0.88904315, ...,  0.1486905 ,\n",
       "           1.08391468,  0.46400565],\n",
       "         [-1.15449642, -0.48364193, -0.99752531, ..., -0.75062264,\n",
       "          -0.50225814,  2.67310756]]),\n",
       "  array([0, 0, 0, ..., 1, 1, 1], dtype=int64),\n",
       "  array([0, 0, 0, ..., 0, 0, 0], dtype=int64)],\n",
       " [LogisticRegression(class_weight={0: 1, 1: 15}, max_iter=400, random_state=2020,\n",
       "                     solver='newton-cg'),\n",
       "  array([[-0.41687478, -0.41084269, -0.08754479, ..., -0.18544762,\n",
       "           0.03349597, -0.29826571],\n",
       "         [-0.76564508,  0.08464212,  0.31399002, ...,  0.48540645,\n",
       "           0.59267849, -0.30802347],\n",
       "         [ 0.9489075 , -0.07104259,  0.02631749, ..., -0.09700922,\n",
       "           0.22768298,  0.62483371],\n",
       "         ...,\n",
       "         [ 0.44996463,  0.48439914,  0.80397445, ...,  1.52472442,\n",
       "           0.95834616, -0.09416919],\n",
       "         [ 1.22012191,  0.03008983,  0.79000055, ..., -0.72391981,\n",
       "          -0.67660207, -0.33725787],\n",
       "         [-1.83080897,  0.16432594,  2.30200126, ...,  1.26542712,\n",
       "           1.22252867, -0.34297257]]),\n",
       "  array([0, 0, 0, ..., 1, 1, 1], dtype=int64),\n",
       "  array([0, 0, 0, ..., 1, 0, 1], dtype=int64)],\n",
       " [LogisticRegression(class_weight={0: 1, 1: 15}, max_iter=400, random_state=2020,\n",
       "                     solver='newton-cg'),\n",
       "  array([[ 0.49941964,  0.02151323,  0.3280098 , ...,  0.64741135,\n",
       "           0.27257746, -0.33683024],\n",
       "         [ 1.49156751,  1.10951068, -0.43923953, ..., -0.20967175,\n",
       "          -0.20843444, -0.07861898],\n",
       "         [-1.02546781,  0.66332729, -0.30982762, ...,  0.0536541 ,\n",
       "           0.0630172 , -0.21452783],\n",
       "         ...,\n",
       "         [-1.74509816, -1.96398531,  4.29277308, ...,  4.58560472,\n",
       "           2.66048655, -0.34297257],\n",
       "         [ 0.82122403,  0.59941843,  1.89828593, ...,  1.19084328,\n",
       "           0.98935501, -0.34686013],\n",
       "         [ 0.73877098,  0.7741523 , -0.31729507, ..., -0.03670837,\n",
       "           0.12551102,  0.72676535]]),\n",
       "  array([0, 0, 0, ..., 1, 1, 1], dtype=int64),\n",
       "  array([0, 0, 0, ..., 1, 1, 0], dtype=int64)],\n",
       " [LogisticRegression(class_weight={0: 1, 1: 15}, max_iter=400, random_state=2020,\n",
       "                     solver='newton-cg'),\n",
       "  array([[ 0.47133979,  0.53378354, -1.10191569, ..., -0.38198636,\n",
       "          -0.03919747,  1.55804078],\n",
       "         [ 1.33437497, -0.7915194 , -0.55046057, ..., -0.30388782,\n",
       "          -0.92463475,  0.62502809],\n",
       "         [-1.48248005, -0.22099397,  1.04404195, ..., -1.83626616,\n",
       "          -0.8684705 , -0.34619924],\n",
       "         ...,\n",
       "         [ 0.71067011,  0.46410728,  0.80647895, ...,  1.59144971,\n",
       "           0.97112732, -0.08289529],\n",
       "         [-1.55967864, -7.99739178,  5.30762033, ...,  5.20666849,\n",
       "          -4.29673913, -0.34297257],\n",
       "         [ 1.00330171, -1.69922815,  0.05708437, ...,  2.52546729,\n",
       "           0.01140104,  0.89719566]]),\n",
       "  array([0, 0, 0, ..., 1, 1, 1], dtype=int64),\n",
       "  array([0, 0, 0, ..., 1, 1, 1], dtype=int64)],\n",
       " [LogisticRegression(class_weight={0: 1, 1: 15}, max_iter=400, random_state=2020,\n",
       "                     solver='newton-cg'),\n",
       "  array([[-0.67352382,  0.51826225, -0.98539269, ...,  0.14606111,\n",
       "           0.07643378,  0.32102146],\n",
       "         [ 1.17108725,  0.05977242,  0.5049858 , ...,  0.51091541,\n",
       "           0.20253602, -0.32357368],\n",
       "         [ 1.12707586,  0.69000508, -0.73439   , ..., -0.21991664,\n",
       "          -0.00808572,  1.05036525],\n",
       "         ...,\n",
       "         [-1.59669108, -7.78477886,  4.5187322 , ...,  5.5149345 ,\n",
       "          -3.5853159 , -0.34297257],\n",
       "         [ 1.02516028, -1.37636993,  2.00150636, ...,  1.25513882,\n",
       "           0.4270082 , -0.34297257],\n",
       "         [-1.1243358 , -2.99665901,  2.76351195, ...,  4.36749331,\n",
       "           1.12664791, -0.3262561 ]]),\n",
       "  array([0, 0, 0, ..., 1, 1, 1], dtype=int64),\n",
       "  array([0, 0, 0, ..., 1, 1, 1], dtype=int64)],\n",
       " [LogisticRegression(class_weight={0: 1, 1: 15}, max_iter=400, random_state=2020,\n",
       "                     solver='newton-cg'),\n",
       "  array([[-1.3297433 ,  0.49545292, -0.39552091, ..., -0.11849448,\n",
       "           0.11436705,  0.15852175],\n",
       "         [-0.28763599,  0.51299049, -0.32065229, ...,  0.2493946 ,\n",
       "           0.03698081, -0.24072993],\n",
       "         [-0.32824249,  0.08156748,  0.20529502, ...,  0.71444307,\n",
       "           0.76432157, -0.34686013],\n",
       "         ...,\n",
       "         [ 1.30366788, -0.06138917,  0.08268005, ...,  0.05363469,\n",
       "           0.3302583 ,  0.38053989],\n",
       "         [-0.97267095, -1.40737112, -0.88904315, ...,  0.1486905 ,\n",
       "           1.08391468,  0.46400565],\n",
       "         [-1.15449642, -0.48364193, -0.99752531, ..., -0.75062264,\n",
       "          -0.50225814,  2.67310756]]),\n",
       "  array([0, 0, 0, ..., 1, 1, 1], dtype=int64),\n",
       "  array([0, 0, 0, ..., 0, 0, 0], dtype=int64)]]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3646a40f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(logs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e96619f",
   "metadata": {},
   "source": [
    "가중치 10의 결과는 10 ~ 14번째 항목들이다.  \n",
    "이중에서 11 인덱스의결과, 즉 가중치 2, Fold2의 결과가 가장 좋았다. 그 결과를 살펴보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ba7b39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d534d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0c7eda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca389705",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f010ab52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed833e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
